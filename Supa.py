import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf
import torch
import torch.nn as nn
import torch.optim as optim

st.set_page_config(page_title="Baccarat AI", layout="wide")
if "new_result" not in st.session_state:
    st.session_state["new_result"] = ""
if "trained_model" not in st.session_state:
    st.session_state["trained_model"] = None

# Sidebar menu
st.sidebar.title("üîß Tu·ª≥ ch·ªçn m√¥ h√¨nh d·ª± ƒëo√°n")
selected_model = st.sidebar.radio("Ch·ªçn m√¥ h√¨nh", ["T·ªïng quan", "Markov Chain", "RNN (LSTM)", "GRU", "RNN (PyTorch)"])
show_markov = st.sidebar.checkbox("üîÅ B·∫≠t Markov Chain", value=(selected_model == "Markov Chain"))
show_lstm = st.sidebar.checkbox("üîÆ B·∫≠t RNN (LSTM)", value=(selected_model == "RNN (LSTM)"))
show_gru = st.sidebar.checkbox("üîÅ B·∫≠t GRU", value=(selected_model == "GRU"))
show_torch = st.sidebar.checkbox("üî• B·∫≠t RNN (PyTorch)", value=(selected_model == "RNN (PyTorch)"))
epochs = st.sidebar.slider("S·ªë epoch hu·∫•n luy·ªán", min_value=5, max_value=50, value=15)

if "data" not in st.session_state:
    st.session_state["data"] = []

st.title("üé≤ Ph√¢n t√≠ch & D·ª± ƒëo√°n Baccarat")
st.text_input("Nh·∫≠p k·∫øt qu·∫£ (Player, Banker, Tie):", key="new_result")

if st.session_state["new_result"]:
    result = st.session_state["new_result"].strip().capitalize()
    if result in ["Player", "Banker", "Tie"]:
        st.session_state["data"].append(result)
        st.success(f"‚úÖ ƒê√£ th√™m: {result}")
    else:
        st.error("‚ùå K·∫øt qu·∫£ kh√¥ng h·ª£p l·ªá.")

# X√≥a d·ªØ li·ªáu & ho√†n t√°c
if st.button("üóëÔ∏è X√≥a to√†n b·ªô d·ªØ li·ªáu"):
    st.session_state["data"] = []
    st.success("‚úÖ ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu.")

if st.session_state["data"]:
    last_result = st.session_state["data"][-1]
    if st.button(f"‚Ü©Ô∏è Ho√†n t√°c k·∫øt qu·∫£ cu·ªëi: {last_result}"):
        st.session_state["data"].pop()
        st.success(f"‚úÖ ƒê√£ ho√†n t√°c: {last_result}")

st.subheader("üìã D·ªØ li·ªáu hi·ªán t·∫°i")
if st.session_state["data"]:
    df_history = pd.DataFrame({"K·∫øt qu·∫£": st.session_state["data"]})
    st.dataframe(df_history)
else:
    st.info("Ch∆∞a c√≥ d·ªØ li·ªáu.")

# T·ªïng quan
if selected_model == "T·ªïng quan":
    st.subheader("üìä T·ªïng quan h·ªá th·ªëng")
    st.markdown("""
    - ‚úÖ Nh·∫≠p k·∫øt qu·∫£ Baccarat theo th·ªùi gian th·ª±c
    - üîÅ Ph√¢n t√≠ch Markov Chain ƒë·ªÉ hi·ªÉu xu h∆∞·ªõng chuy·ªÉn ti·∫øp
    - üîÆ D·ª± ƒëo√°n k·∫øt qu·∫£ ti·∫øp theo b·∫±ng RNN (LSTM, GRU, PyTorch)
    - üìà Hi·ªÉn th·ªã x√°c su·∫•t d·ª± ƒëo√°n
    - üß≠ Tu·ª≥ ch·ªçn b·∫≠t/t·∫Øt t·ª´ng m√¥ h√¨nh trong sidebar
    """)

# Markov Chain
def build_markov_chain(data):
    states = ["Player", "Banker", "Tie"]
    matrix = pd.DataFrame(0, index=states, columns=states)
    for i in range(len(data) - 1):
        matrix.loc[data[i], data[i + 1]] += 1
    prob_matrix = matrix.div(matrix.sum(axis=1), axis=0).fillna(0)
    return matrix, prob_matrix

if show_markov:
    st.subheader("üîÅ Ph√¢n t√≠ch Markov Chain")
    if len(st.session_state["data"]) >= 2:
        count_matrix, prob_matrix = build_markov_chain(st.session_state["data"])
        st.dataframe(prob_matrix.style.format("{:.2f}"))
        fig, ax = plt.subplots()
        sns.heatmap(prob_matrix, annot=True, cmap="Blues", fmt=".2f", ax=ax)
        st.pyplot(fig)
    else:
        st.info("C·∫ßn √≠t nh·∫•t 2 k·∫øt qu·∫£.")

# TensorFlow RNN
def encode_sequence(data):
    mapping = {"Player": 0, "Banker": 1, "Tie": 2}
    return [mapping[d] for d in data if d in mapping]

def create_sequences(encoded, seq_length=5):
    X, y = [], []
    for i in range(len(encoded) - seq_length):
        X.append(encoded[i:i+seq_length])
        y.append(encoded[i+seq_length])
    return np.array(X).reshape(-1, seq_length, 1), np.array(y)

def build_model(model_type="LSTM", seq_length=5, num_classes=3):
    RNNLayer = tf.keras.layers.LSTM if model_type == "LSTM" else tf.keras.layers.GRU
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(seq_length, 1)),
        RNNLayer(64),
        tf.keras.layers.Dense(32, activation='relu'),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def train_tf_model(data, model_type="LSTM", seq_length=5, epochs=30):
    encoded = encode_sequence(data)
    X, y = create_sequences(encoded, seq_length)
    model = build_model(model_type, seq_length)
    history = model.fit(X, y, epochs=epochs, verbose=0)
    return model, history

def predict_tf(model, data, seq_length=5):
    encoded = encode_sequence(data)
    if len(encoded) < seq_length:
        return "Kh√¥ng ƒë·ªß d·ªØ li·ªáu", [0, 0, 0]
    input_seq = np.array(encoded[-seq_length:]).reshape(1, seq_length, 1)
    pred = model.predict(input_seq)[0]
    mapping = {0: "Player", 1: "Banker", 2: "Tie"}
    return mapping[np.argmax(pred)], pred

# PyTorch RNN
class RNNModelTorch(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, output_size=3):
        super().__init__()
        self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Linear(32, output_size)
        )

    def forward(self, x):
        out, _ = self.rnn(x)
        out = out[:, -1, :]
        return self.fc(out)

def train_torch_model(data, seq_length=5, epochs=30):
    encoded = encode_sequence(data)
    X, y = create_sequences(encoded, seq_length)
    X = torch.tensor(X, dtype=torch.float32)
    y = torch.tensor(y, dtype=torch.long)

    model = RNNModelTorch()
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    loss_fn = nn.CrossEntropyLoss()

    for _ in range(epochs):
        model.train()
        optimizer.zero_grad()
        output = model(X)
        loss = loss_fn(output, y)
        loss.backward()
        optimizer.step()
    return model

def predict_torch(model, data, seq_length=5):
    encoded = encode_sequence(data)
    if len(encoded) < seq_length:
        return "Kh√¥ng ƒë·ªß d·ªØ li·ªáu", [0, 0, 0]
    input_seq = torch.tensor(encoded[-seq_length:], dtype=torch.float32).reshape(1, seq_length, 1)
    model.eval()
    with torch.no_grad():
        output = model(input_seq)
        probs = torch.softmax(output, dim=1).numpy()[0]
    mapping = {0: "Player", 1: "Banker", 2: "Tie"}
    return mapping[np.argmax(probs)], probs

# D·ª± ƒëo√°n theo th·ªëng k√™ ƒë∆°n gi·∫£n
def baseline_prediction(data):
    if not data:
        return "Kh√¥ng c√≥ d·ªØ li·ªáu"
    return max(set(data), key=data.count)

if st.button("üìä D·ª± ƒëo√°n theo t·∫ßn su·∫•t"):
    baseline = baseline_prediction(st.session_state["data"])
    st.info(f"üîç D·ª± ƒëo√°n theo th·ªëng k√™: {baseline}")

# Hi·ªán k·∫øt qu·∫£ d·ª± ƒëo√°n
if show_lstm or show_gru:
    model_type = "LSTM" if show_lstm else "GRU"
    st.subheader(f"üîÆ D·ª± ƒëo√°n Baccarat b·∫±ng {model_type}")
    if len(st.session_state["data"]) >= 10:
        if st.button("üîÆ D·ª± ƒëo√°n ti·∫øp theo"):
            if st.session_state["trained_model"] is None:
                model, history = train_tf_model(st.session_state["data"], model_type, epochs=epochs)
                st.session_state["trained_model"] = model
                accuracy = history.history["accuracy"][-1]
                st.session_state["accuracy"] = accuracy
                st.write(f"‚úÖ ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh {model_type}: {round(accuracy * 100, 2)}%")
            else:
                st.write("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr∆∞·ªõc ƒë√≥.")
                accuracy = st.session_state.get("accuracy", None)
                if accuracy is not None:
                    st.write(f"‚úÖ ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh {model_type}: {round(accuracy * 100, 2)}%")
                else:
                    st.info("‚ÑπÔ∏è Ch∆∞a c√≥ th√¥ng tin ƒë·ªô ch√≠nh x√°c.")
    else:
        st.warning("‚ö†Ô∏è C·∫ßn √≠t nh·∫•t 10 k·∫øt qu·∫£.")

